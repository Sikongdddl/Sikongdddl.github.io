---
title: 星火营干货及近日进展
description: 也算周报了（笑）
date: 2023-08-20

categories:
    - paper
---
## 为什么这篇不是论文笔记
科大讯飞这边日程排的又满又不科学 很浪费时间
加上最近接到了电话 
这俩事都值得汇报一下 都挺大的 就没去读论文（笑）
## 讯飞星火大模型相关
去年12月项目开始，5月6日发布13B参数量模型，8月15日发布65B参数量模型

效果低于GPT3.5 但是低的不多 比国内其他大模型还是好一些的

借了华为一部分算力资源支持 加上讯飞常年做输入法和语音识别，训练数据质量很高，清洗数据方法也很成熟 所以虽然仓促但是能做出来

## 星火营相关
成员基本是全国985211的硕士博士生 本科生偏少
很多人都是带着活过来这边 一边被老板push一边做这边的事（笑）

> 8.15-8.17上大课 

除了第一天讲过一些大模型相关的算法和知识之外 都是讲座性质的介绍课程 比较无聊（笑）

讲了大模型的发展沿革（BERT系和GPT系）

transformer诞生后 

BERT系做一些参数量相对没有那么夸张的大模型 做encoder only，识别任务更多一些 必须fine-tune 预训练方式是mask后完形填空 或根据上一句话写出下一句话 标注成本高

GPT系做参数量很夸张的大模型（GPT3就有175B） decoder only，做生成任务更多一些

GPT系能做出来原因主要是：
* transformer的Encoder本身叠不深 不全是钱的问题 到100B这种参数量的encoder-only训练不起来 
* GPT系泛化能力比BERT系好（不用finetune）而且预训练任务更简单


> 8.18“测评” 

分成7人小组 想prompt 想评价体系横向比较讯飞大模型和GPT3.5的情况 代码比较简单 一些基本的API调用 但是工作量安排不合理 对prompt量要求较大 全员加班 下班时间11：00-2：00不定 我们十二点搞好的

> 8.19-8.24做项目 

我和宋的选题是给大模型做插件 技术上也不复杂 总体上要做的是截获用户的prompt，润色后丢给第三方处理（如询问天气）或交给大模型，获得更丰富有效的回答 主要考察想象力（笑）

> 奖金：（全组奖金 税前）

16组进8 

4-8名20000

2-3名50000

1名100000

组队运气不好 本来最厉害的大哥（交大18级硕士毕业，去北京工作了几年回来读博）被老板叫回去了 除了宋能帮到比较大的忙以外 其它几位朋友基础都比较差

现在项目是我在架构和管理 进度比较乐观 工作强度也不大 估计明天就能做完 但应该不考虑奖金的事情了 真能拿到奖金的话回来就充公（笑）

也算是有收获的 感觉自己和别人（尤其是比较菜的朋友）交流的能力显著增强 也慢慢明白要怎么和更厉害的人相处才让双方都舒服

## 关于戴院士组里来交大就职的老师
写到这才发现我不知道她叫什么名字（笑）

8月19日晚收到了面试电话 简单交流了下

交流内容大概包括：
* 关于推免资格（我一接到电话就全交代了 她看简历并不知道第六学期的事 但她还是坚持把电话打完了（笑））
* 代码能力（她说我挺能写码的 是她想找的类型）
* 为什么挺能写码但是GPA不高（致远+最后一学期专业课组队失利 她听我说组队就明白了）
* 之前的研究方向和科研经历
* 交大的保研流程常识（主要是我在介绍 好像她并不清楚）
* 为什么这么晚了还没确定接收（于是我又说了一遍我最近这几个月的叠加态）
* 问王老师有几个名额（实话实说了我）
* 她和我一开始一样 也没想明白我怎么能报到她这种24年入职的老师 我说报戴院士 挂大老板 她有点没反应过来愣了一下 可能之前没考虑过这种展开（笑）
* 研究方向偏硬件会不会不喜欢（介绍了硬件层面加速算法的一些知识 以及说那边做纯算法的太卷了 博士得发十篇 做做硬件还没那么卷 我说挺感兴趣 如果这玩意能让大模型更好训练就好了）
* 会不会顾虑年轻老师资源少（我说喜欢被push 年轻老师在学生身上花的时间多）

第一次电话结束后约十分钟又来了一通电话 问我为什么不去杨老师这边的其它小老板那里（马老师 晏老师和沈老师） 看起来还是没有完全理解交大的流程 我解释说被CS挂简历了 去不了计算机系

最后的结论：
* 她说这波有好多学生 所以现在不能确定下来（这句话翻来覆去说了好几次 婉拒了属于是） 让我确认拿到推免资格后再联系她一次



